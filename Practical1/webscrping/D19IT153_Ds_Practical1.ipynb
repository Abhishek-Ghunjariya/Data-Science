from selenium import webdriver
from bs4 import BeautifulSoup
import pandas as pd
driver = webdriver.Chrome(executable_path=r'C:/Users/Admin/chromedriver.exe')
products=[]
prices=[] 
ratings=[]
driver.get("https://www.flipkart.com/air-conditioners/pr?sid=j9e,abm,c54&p[]=facets.fulfilled_by%255B%255D%3DFlipkart%2BAssured&p[]=facets.technology%255B%255D%3DInverter&p[]=facets.serviceability%5B%5D%3Dtrue&otracker=categorytree&otracker=nmenu_sub_TVs%20%26%20Appliances_0_Inverter%20AC")
for element in soup.findAll('div', attrs={'class':'_1AtVbE col-12-12'}):
    name=element.find('div', attrs={'class':'_4rR01T'})
    price=element.find('div', attrs={'class':'_30jeq3 _1_WHN1'})
    rating=element.find('div', attrs={'class':'_3LWZlK'})
    try:
        products.append(name.text)
        prices.append(price.text)
        ratings.append(rating.text)
    except:
        continue
a = {'ProductName':products,'Price':prices,'Rating':ratings}
df = pd.DataFrame.from_dict(a, orient='index')
df = df.transpose()
df.to_csv('D19IT153_DS_PR1.csv', index=False, encoding='utf-8')
